{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing different libraries\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the dataset(csv file) to the torch.tensor form\n",
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, transform1=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.transform1 = transform1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        image = torch.Tensor(self.landmarks_frame.iloc[idx, 1:].values.reshape(1,28,28))\n",
    "        label = self.landmarks_frame.iloc[idx, 0].reshape(1)\n",
    "        label = torch.LongTensor(label)\n",
    "        image =self.transform1(image)\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        label = label[0]\n",
    "        landmarks = (image, label)\n",
    "        \n",
    "        return landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the train dataset and test dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = FashionMNIST(csv_file='fdata/fashion-mnist_train.csv',\n",
    "                             root_dir='fdata/',\n",
    "                             transform=transform,\n",
    "                             transform1=transforms.ToPILImage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST(csv_file='fdata/fashion-mnist_test.csv',\n",
    "                            root_dir='fdata/',\n",
    "                            transform=transform,\n",
    "                            transform1=transforms.ToPILImage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the train and test dataset\n",
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = 10\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True)\n",
    "\n",
    "test_load = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swish activation function\n",
    "def swish(x):\n",
    "    return x * F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model class\n",
    "torch.manual_seed(0)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        nn.init.xavier_uniform(self.cnn1.weight)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        #self.dr1 = nn.Dropout2d(0.07)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        nn.init.xavier_uniform(self.cnn2.weight)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        #self.dr2 = nn.Dropout2d(0.07)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        nn.init.xavier_uniform(self.cnn3.weight)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        #self.dr3 = nn.Dropout2d(0.07)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        #self.cnn4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        #nn.init.xavier_uniform(self.cnn4.weight)\n",
    "        #self.bn4 = nn.BatchNorm1d(32)\n",
    "        #self.dr4 = nn.Dropout2d(0.07)\n",
    "        #self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(32*7*7, 10)\n",
    "        self.bn5 = nn.BatchNorm1d(10)\n",
    "        nn.init.xavier_uniform(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.cnn1(x)\n",
    "        out = self.bn1(out)\n",
    "        #out = self.dr1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.pool1(out)\n",
    "        \n",
    "        out = self.cnn2(out)\n",
    "        out = self.bn2(out)\n",
    "        #out = self.dr2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.pool2(out)\n",
    "        \n",
    "        out = self.cnn3(out)\n",
    "        out = self.bn3(out)\n",
    "        #out = self.dr3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        #out = self.cnn4(out)\n",
    "        #out = self.bn4(out)\n",
    "        #out = self.dr4(out)\n",
    "        #out = self.relu4(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.bn5(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the model class\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the loss class\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "#instantiating the optimizer class\n",
    "learing_rate = 0.06\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learing_rate)\n",
    "\n",
    "print(len(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations 500, loss 0.3865665793418884, accuracy 88.31\n",
      "iterations 1000, loss 0.32070326805114746, accuracy 89.69\n",
      "iterations 1500, loss 0.3125731647014618, accuracy 90.71000000000001\n",
      "iterations 2000, loss 0.31422320008277893, accuracy 90.24\n",
      "iterations 2500, loss 0.2363504022359848, accuracy 90.91\n",
      "iterations 3000, loss 0.30532631278038025, accuracy 90.94\n",
      "iterations 3500, loss 0.13100895285606384, accuracy 91.07\n",
      "iterations 4000, loss 0.1430157721042633, accuracy 90.89\n",
      "iterations 4500, loss 0.06790616363286972, accuracy 91.0\n",
      "iterations 5000, loss 0.18560124933719635, accuracy 91.13\n",
      "iterations 5500, loss 0.08033032715320587, accuracy 91.05\n",
      "iterations 6000, loss 0.15602754056453705, accuracy 90.9\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images, labels) in enumerate(train_load):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        #testing the model\n",
    "        if (iter%500) == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_load:\n",
    "                images = Variable(images)\n",
    "            \n",
    "                outputs = model(images)\n",
    "                _, predicts = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicts == labels).sum()\n",
    "            accuracy = 100 * (correct.item() / total)\n",
    "                \n",
    "            print('iterations {}, loss {}, accuracy {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max accuracy = 91.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
